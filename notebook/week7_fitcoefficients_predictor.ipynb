{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split results of simulated data\n",
      "LogisticRegression accuracy is 0.782\n",
      "LogisticRegression log_loss is 0.518\n",
      "LogisticRegression auc is 0.829\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "\n",
    "#  Fit coefficients and predict NN by the simulated new dataset\n",
    "\n",
    "################################\n",
    "\n",
    "# 1. import data and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read CSV train data file into DataFrame\n",
    "train_df = pd.read_csv(\"../data/kaggle_titanic/train.csv\")\n",
    "\n",
    "# Read CSV test data file into DataFrame\n",
    "test_df = pd.read_csv(\"../data/kaggle_titanic/test.csv\")\n",
    "\n",
    "# 2. data quality check\n",
    "# check missing values in train data\n",
    "train_df.isnull().sum()\n",
    "# data adjustment\n",
    "train_data = train_df.copy()\n",
    "train_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\n",
    "train_data[\"Embarked\"].fillna(train_df['Embarked'].value_counts().idxmax(), inplace=True)\n",
    "train_data.drop('Cabin', axis=1, inplace=True)\n",
    "# double check missing values in adjusted train data\n",
    "train_data.isnull().sum()\n",
    "\n",
    "## Create categorical variable for traveling alone\n",
    "train_data['TravelAlone'] = np.where((train_data[\"SibSp\"]+train_data[\"Parch\"])>0, 0, 1)\n",
    "train_data.drop('SibSp', axis=1, inplace=True)\n",
    "train_data.drop('Parch', axis=1, inplace=True)\n",
    "\n",
    "#create categorical variables and drop some variables\n",
    "\n",
    "training = pd.get_dummies(train_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\n",
    "training.drop('Sex_female', axis=1, inplace=True)\n",
    "training.drop('PassengerId', axis=1, inplace=True)\n",
    "training.drop('Name', axis=1, inplace=True)\n",
    "training.drop('Ticket', axis=1, inplace=True)\n",
    "\n",
    "final_train = training\n",
    "\n",
    "# apply change to test data\n",
    "test_df.isnull().sum()\n",
    "\n",
    "test_data = test_df.copy()\n",
    "test_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\n",
    "test_data[\"Fare\"].fillna(train_df[\"Fare\"].median(skipna=True), inplace=True)\n",
    "test_data.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "test_data['TravelAlone']=np.where((test_data[\"SibSp\"]+test_data[\"Parch\"])>0, 0, 1)\n",
    "test_data.drop('SibSp', axis=1, inplace=True)\n",
    "test_data.drop('Parch', axis=1, inplace=True)\n",
    "\n",
    "testing = pd.get_dummies(test_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\n",
    "testing.drop('Sex_female', axis=1, inplace=True)\n",
    "testing.drop('PassengerId', axis=1, inplace=True)\n",
    "testing.drop('Name', axis=1, inplace=True)\n",
    "testing.drop('Ticket', axis=1, inplace=True)\n",
    "\n",
    "final_test = testing\n",
    "\n",
    "final_test.head()\n",
    "\n",
    "# 3. data analysis\n",
    "\n",
    "# add 16 boundary for age\n",
    "final_train['IsMinor'] = np.where(final_train['Age'] <= 16, 1, 0)\n",
    "final_test['IsMinor'] = np.where(final_test['Age'] <= 16, 1, 0)\n",
    "\n",
    "# 4. logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# model evaluation procedures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n",
    "\n",
    "# create X (features) and y (response)\n",
    "Selected_features = ['Age', 'TravelAlone', 'Pclass_1', 'Pclass_2', 'Embarked_C',\n",
    "                     'Embarked_S', 'Sex_male', 'IsMinor']\n",
    "X = final_train[Selected_features]\n",
    "y = final_train['Survived']\n",
    "\n",
    "# use train/test split with different random_state values\n",
    "# we can change the random_state values that changes the accuracy scores\n",
    "# the scores change a lot, this is why testing scores is a high-variance estimate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# check classification scores of logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\n",
    "# print('Train/Test split results:')\n",
    "# print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\n",
    "# print(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\n",
    "# print(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))\n",
    "\n",
    "# get logistic regression coefficients and intercept\n",
    "coef = logreg.coef_\n",
    "inter = logreg.intercept_\n",
    "\n",
    "# calculate mean and std from the input data and simulate x\n",
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()\n",
    "X_simulated = np.random.normal(train_mean, train_std, size=(len(X_train), len(train_mean)))\n",
    "\n",
    "# calculate the output using simulated inputs and fitted coefficients\n",
    "y_simulated = 1/(1 + np.exp(- (np.matmul(X_simulated,np.transpose(coef)) + inter)))\n",
    "\n",
    "# simulate y by fitted coefficients ouputs\n",
    "y_round = np.random.binomial(1,y_simulated)\n",
    "y_trainnew = y_round.reshape((len(y_round),))\n",
    "\n",
    "# check classification scores and set benchmark for logistic regression again\n",
    "lognew = LogisticRegression()\n",
    "lognew.fit(X_simulated, y_trainnew)\n",
    "y_pred = lognew.predict(X_test)\n",
    "y_pred_proba = lognew.predict_proba(X_test)[:, 1]\n",
    "[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\n",
    "print('Train/Test split results of simulated data')\n",
    "print(lognew.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(lognew.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\n",
    "print(lognew.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | linear1 | Linear  | 180   \n",
      "1 | linear2 | Linear  | 21    \n",
      "2 | sigmoid | Sigmoid | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87d5a971f8f4630b0bdc25a2d7feb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of basic neural network using the simulated input: 74 %\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "\n",
    "# basic neural network predictor\n",
    "\n",
    "#####################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# change train test data for neural network\n",
    "train_loader_x = torch.tensor(X_simulated).float()\n",
    "train_loader_y = torch.tensor(y_trainnew).float()\n",
    "test_loader_x = torch.tensor(X_test.values).float()\n",
    "test_loader_y = torch.tensor(y_test.values).float()\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_loader_x, train_loader_y))\n",
    "test_loader = DataLoader(TensorDataset(test_loader_x, test_loader_y))\n",
    "\n",
    "class BasicNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(8, 20)\n",
    "        self.linear2 = nn.Linear(20, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        inputs, labels = batch\n",
    "        # reshape train data y\n",
    "        labels = labels.view(1,-1)\n",
    "\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    #def training_epoch_end(self, loss):\n",
    "        # do something with all training_step outputs\n",
    "        # print(self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=False, logger=False))\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "NN = BasicNN()\n",
    "trainer = pl.Trainer(max_epochs=100)\n",
    "trainer.fit(NN, train_loader)\n",
    "\n",
    "# test performance\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        # reshape test data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        outputs = NN(inputs)\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of basic neural network using the simulated input: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name     | Type    | Params\n",
      "-------------------------------------\n",
      "0 | linear1  | Linear  | 900   \n",
      "1 | sigmoid1 | Sigmoid | 0     \n",
      "2 | linear2  | Linear  | 2 K   \n",
      "3 | sigmoid2 | Sigmoid | 0     \n",
      "4 | linear3  | Linear  | 210   \n",
      "5 | sigmoid3 | Sigmoid | 0     \n",
      "6 | linear4  | Linear  | 55    \n",
      "7 | sigmoid4 | Sigmoid | 0     \n",
      "8 | linear5  | Linear  | 6     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c820124ee2e450c8e92cc5b79fdd771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of deep neural network using the simulated input: 55 %\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "\n",
    "# deep neural network predictor\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "class DNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(8, 100)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(100, 20)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.linear3 = nn.Linear(20, 10)\n",
    "        self.sigmoid3 = nn.Sigmoid()\n",
    "        self.linear4 = nn.Linear(10, 5)\n",
    "        self.sigmoid4 = nn.Sigmoid()\n",
    "        self.linear5 = nn.Linear(5, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid1(self.linear2(x))\n",
    "        x = self.sigmoid2(self.linear3(x))\n",
    "        x = self.sigmoid3(self.linear4(x))\n",
    "        x = self.sigmoid4(self.linear5(x))\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        inputs, labels = batch\n",
    "        # reshape train data y\n",
    "        labels = labels.view(1,-1)\n",
    "\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    #def training_epoch_end(self, loss):\n",
    "        # do something with all training_step outputs\n",
    "        #print(self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=False, logger=False))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "DeepNN = DNN()\n",
    "trainer = pl.Trainer(max_epochs=10)\n",
    "trainer.fit(DeepNN, train_loader)\n",
    "\n",
    "# test performance\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        # reshape test data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        outputs = DeepNN(inputs)\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of deep neural network using the simulated input: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name     | Type           | Params\n",
      "--------------------------------------------\n",
      "0 | blinear1 | BayesianLinear | 3 K   \n",
      "1 | sigmoid1 | Sigmoid        | 0     \n",
      "2 | blinear2 | BayesianLinear | 8 K   \n",
      "3 | sigmoid2 | Sigmoid        | 0     \n",
      "4 | blinear3 | BayesianLinear | 840   \n",
      "5 | sigmoid3 | Sigmoid        | 0     \n",
      "6 | blinear4 | BayesianLinear | 220   \n",
      "7 | sigmoid4 | Sigmoid        | 0     \n",
      "8 | blinear5 | BayesianLinear | 24    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7123f04f2ba1423bb77dd59af06a1f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of bayesian neural network using the simulated input: 55 %\n"
     ]
    }
   ],
   "source": [
    "from blitz.modules import BayesianLinear\n",
    "\n",
    "class LitBayesian(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.blinear1 = BayesianLinear(input_dim, 100)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.blinear2 = BayesianLinear(100, 20)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.blinear3 = BayesianLinear(20, 10)\n",
    "        self.sigmoid3 = nn.Sigmoid()\n",
    "        self.blinear4 = BayesianLinear(10,5)\n",
    "        self.sigmoid4 = nn.Sigmoid()\n",
    "        self.blinear5 = BayesianLinear(5, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.blinear1(x)\n",
    "        x2 = self.sigmoid1(self.blinear2(x1))\n",
    "        x3 = self.sigmoid2(self.blinear3(x2))\n",
    "        x4 = self.sigmoid3(self.blinear4(x3))\n",
    "        x5 = self.sigmoid4(self.blinear5(x4))\n",
    "        return x5\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        inputs, labels = batch\n",
    "        # reshape train data y\n",
    "        labels = labels.view(1, -1)\n",
    "\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    #def training_epoch_end(self, loss):\n",
    "        # do something with all training_step outputs\n",
    "        #print(self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=False, logger=False))\n",
    "\n",
    "BayesianNN = LitBayesian(8,1)\n",
    "trainer = pl.Trainer(max_epochs=10)\n",
    "trainer.fit(BayesianNN, train_loader)\n",
    "\n",
    "# test performance\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        # reshape test data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        outputs = BayesianNN(inputs)\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of bayesian neural network using the simulated input: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
