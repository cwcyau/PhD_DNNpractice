{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.9.11          |           py37_0         147 KB  conda-forge\n",
      "    ninja-1.9.0                |       h04f5b5a_0          94 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         241 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ninja              conda-forge/osx-64::ninja-1.9.0-h04f5b5a_0\n",
      "  pytorch            pytorch/osx-64::pytorch-1.6.0-py3.7_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ninja-1.9.0          | 94 KB     | ##################################### | 100% \n",
      "certifi-2019.9.11    | 147 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "\n",
    "# Implement a logistic regression\n",
    "\n",
    "#########################################\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# simulate a data set for a logistic regression model with 5 dimension:\n",
    "# assume covariance is an identity matrix\n",
    "sigma1 = np.identity(5)\n",
    "# mean is an array of 0\n",
    "mean1 = np.zeros(5)\n",
    "# number of samples are 200\n",
    "n1 = 200\n",
    "# generate n gaussian distributed data points\n",
    "x = np.random.multivariate_normal(mean1, sigma1, n1)\n",
    "\n",
    "# split the training test data by half\n",
    "# simulate y by p = 0.5\n",
    "y = np.random.choice([0, 1], size=n1, p=[.5, .5])\n",
    "\n",
    "# split data\n",
    "train_x = x[0:100,:]\n",
    "train_y = y[0:100]\n",
    "test_x = x[100:200,:]\n",
    "test_y = y[100:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################\n",
    "# run standard logistic regression on simulated data\n",
    "#############################################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear', random_state=0).fit(train_x, train_y)\n",
    "# intercept\n",
    "model.intercept_\n",
    "# coefficient\n",
    "model.coef_\n",
    "# predicted probability\n",
    "model.predict_proba(test_x)\n",
    "# predicted value\n",
    "model.predict(test_x)\n",
    "# predicted accuracy score for test data\n",
    "model.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 0.007\n",
      "[1,    40] loss: 0.002\n",
      "[1,    60] loss: 0.006\n",
      "[1,    80] loss: 0.004\n",
      "[1,   100] loss: 0.005\n",
      "[2,    20] loss: 0.006\n",
      "[2,    40] loss: 0.002\n",
      "[2,    60] loss: 0.005\n",
      "[2,    80] loss: 0.004\n",
      "[2,   100] loss: 0.004\n",
      "[3,    20] loss: 0.005\n",
      "[3,    40] loss: 0.001\n",
      "[3,    60] loss: 0.004\n",
      "[3,    80] loss: 0.003\n",
      "[3,   100] loss: 0.003\n",
      "[4,    20] loss: 0.004\n",
      "[4,    40] loss: 0.001\n",
      "[4,    60] loss: 0.003\n",
      "[4,    80] loss: 0.003\n",
      "[4,   100] loss: 0.003\n",
      "[5,    20] loss: 0.004\n",
      "[5,    40] loss: 0.001\n",
      "[5,    60] loss: 0.003\n",
      "[5,    80] loss: 0.003\n",
      "[5,   100] loss: 0.003\n",
      "Finished Training\n",
      "Accuracy of the network 100 train numbers: 52 %\n",
      "Accuracy of the network 100 test numbers: 47 %\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# apply neural network\n",
    "#############################################\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# use a trial single layer NN first\n",
    "class Logistictest(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Logistictest, self).__init__()\n",
    "        self.linear = nn.Linear(5,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs\n",
    "\n",
    "model = Logistictest()\n",
    "\n",
    "# define a loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# make dataset iterable\n",
    "train_loader_x = Variable(torch.Tensor(train_x))\n",
    "train_loader_y = Variable(torch.Tensor(train_y))\n",
    "test_loader_x = Variable(torch.Tensor(test_x))\n",
    "test_loader_y = Variable(torch.Tensor(test_y))\n",
    "\n",
    "# model training\n",
    "iter = 0\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(zip(train_loader_x,train_loader_y)):\n",
    "        inputs, labels = data\n",
    "        # reshape train data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Compute Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:  # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# make predictions\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in zip(train_loader_x,train_loader_y):\n",
    "        inputs, labels = data\n",
    "        # reshape test data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network 100 train numbers: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in zip(test_loader_x,test_loader_y):\n",
    "        inputs, labels = data\n",
    "        # reshape test data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network 100 test numbers: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 0.005\n",
      "[1,    40] loss: 0.003\n",
      "[1,    60] loss: 0.007\n",
      "[1,    80] loss: 0.005\n",
      "[1,   100] loss: 0.005\n",
      "[2,    20] loss: 0.004\n",
      "[2,    40] loss: 0.002\n",
      "[2,    60] loss: 0.005\n",
      "[2,    80] loss: 0.004\n",
      "[2,   100] loss: 0.004\n",
      "[3,    20] loss: 0.003\n",
      "[3,    40] loss: 0.002\n",
      "[3,    60] loss: 0.004\n",
      "[3,    80] loss: 0.003\n",
      "[3,   100] loss: 0.004\n",
      "[4,    20] loss: 0.003\n",
      "[4,    40] loss: 0.002\n",
      "[4,    60] loss: 0.004\n",
      "[4,    80] loss: 0.003\n",
      "[4,   100] loss: 0.003\n",
      "[5,    20] loss: 0.003\n",
      "[5,    40] loss: 0.002\n",
      "[5,    60] loss: 0.003\n",
      "[5,    80] loss: 0.003\n",
      "[5,   100] loss: 0.003\n",
      "Finished Training\n",
      "Accuracy of the network 100 train numbers: 59 %\n",
      "Accuracy of the network 100 test numbers: 55 %\n",
      "[1,    20] loss: 0.003\n",
      "[1,    40] loss: 0.002\n",
      "[1,    60] loss: 0.003\n",
      "[1,    80] loss: 0.003\n",
      "[1,   100] loss: 0.003\n",
      "[2,    20] loss: 0.003\n",
      "[2,    40] loss: 0.002\n",
      "[2,    60] loss: 0.003\n",
      "[2,    80] loss: 0.003\n",
      "[2,   100] loss: 0.003\n",
      "[3,    20] loss: 0.003\n",
      "[3,    40] loss: 0.002\n",
      "[3,    60] loss: 0.003\n",
      "[3,    80] loss: 0.003\n",
      "[3,   100] loss: 0.003\n",
      "[4,    20] loss: 0.003\n",
      "[4,    40] loss: 0.002\n",
      "[4,    60] loss: 0.002\n",
      "[4,    80] loss: 0.002\n",
      "[4,   100] loss: 0.003\n",
      "[5,    20] loss: 0.003\n",
      "[5,    40] loss: 0.002\n",
      "[5,    60] loss: 0.002\n",
      "[5,    80] loss: 0.002\n",
      "[5,   100] loss: 0.003\n",
      "Finished Training\n",
      "Accuracy of the network 100 train numbers: 53 %\n",
      "Accuracy of the network 100 test numbers: 40 %\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# run standard logistic regression on simulated data\n",
    "#############################################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear', random_state=0).fit(train_x, train_y)\n",
    "# intercept\n",
    "model.intercept_\n",
    "# coefficient\n",
    "model.coef_\n",
    "# predicted probability\n",
    "model.predict_proba(test_x)\n",
    "# predicted value\n",
    "model.predict(test_x)\n",
    "# predicted accuracy score for test data\n",
    "model.score(test_x, test_y)\n",
    "\n",
    "#############################################\n",
    "# apply neural network\n",
    "#############################################\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# use a trial single layer NN first\n",
    "class Logistictest(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Logistictest, self).__init__()\n",
    "        self.linear = nn.Linear(5,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs\n",
    "\n",
    "model = Logistictest()\n",
    "\n",
    "# define a loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# make dataset iterable\n",
    "train_loader_x = Variable(torch.Tensor(train_x))\n",
    "train_loader_y = Variable(torch.Tensor(train_y))\n",
    "test_loader_x = Variable(torch.Tensor(test_x))\n",
    "test_loader_y = Variable(torch.Tensor(test_y))\n",
    "\n",
    "# model training\n",
    "iter = 0\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(zip(train_loader_x,train_loader_y)):\n",
    "        inputs, labels = data\n",
    "        # reshape train data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Compute Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:  # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# make predictions\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in zip(train_loader_x,train_loader_y):\n",
    "        inputs, labels = data\n",
    "        # reshape test data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network 100 train numbers: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in zip(test_loader_x,test_loader_y):\n",
    "        inputs, labels = data\n",
    "        # reshape test data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network 100 test numbers: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "#############################################\n",
    "# apply it on a multiple layers DNN\n",
    "#############################################\n",
    "\n",
    "# use multiple layers NN\n",
    "class LogisticDNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LogisticDNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(5, 60)\n",
    "        self.linear2 = nn.Linear(60, 20)\n",
    "        self.linear3 = nn.Linear(20, 10)\n",
    "        self.linear4 = nn.Linear(10, 5)\n",
    "        self.linear5 = nn.Linear(5, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.linear5(x)\n",
    "        return x\n",
    "\n",
    "model = LogisticDNN()\n",
    "\n",
    "# define a loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# model training\n",
    "iter = 0\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(zip(train_loader_x,train_loader_y)):\n",
    "        inputs, labels = data\n",
    "        # reshape train data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Compute Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:  # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# make predictions\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in zip(train_loader_x,train_loader_y):\n",
    "        inputs, labels = data\n",
    "        # reshape test data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network 100 train numbers: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in zip(test_loader_x,test_loader_y):\n",
    "        inputs, labels = data\n",
    "        # reshape test data y\n",
    "        labels = labels.view(1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network 100 test numbers: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
